{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z5ET9vkuZoKD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor, ToPILImage, Normalize\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "X4364U6PeEFh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "FBTBUK1qZ_PG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNIST(root='data', train=True, transform=ToTensor(), download=True)\n",
        "test_dataset = MNIST(root='data', train=False, transform=ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "_QK0vJQ2ZzV7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the dataset"
      ],
      "metadata": {
        "id": "LvqKRJd0a6-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train_dataset[10]\n",
        "img = ToPILImage()(img)\n",
        "print(f\"Image has label: {label}\")\n",
        "print(f\"Shape of the img in dataset: {train_dataset[0][0].shape}\")\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "6fj7mZ4Kaw2F",
        "outputId": "23921fea-c31e-4f1d-c9d1-7380755af751"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image has label: 3\n",
            "Shape of the img in dataset: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f64378d4ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size)"
      ],
      "metadata": {
        "id": "b11uQzCRdDZE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model structure"
      ],
      "metadata": {
        "id": "1YG_iAhqe8ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=3), nn.BatchNorm2d(32), nn.PReLU(), nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=3), nn.BatchNorm2d(64), nn.PReLU(), nn.MaxPool2d(2))\n",
        "        self.layer3 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=3), nn.BatchNorm2d(64), nn.PReLU())\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear = nn.Sequential(nn.Linear(12544, 2048), nn.PReLU(), nn.Linear(2048, 256), nn.PReLU(), nn.Dropout(), nn.Linear(256, 10))\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear(x)\n",
        "        logits = self.softmax(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ICtOGXH5e7sU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training module"
      ],
      "metadata": {
        "id": "n6htHCjnhqhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, loss_fn):\n",
        "    best_loss = 1000\n",
        "    for epoch in range(epochs):\n",
        "        avg_loss = 0\n",
        "        print(f\"======= Epoch {epoch+1} =======\")\n",
        "        size = len(dataloader.dataset)\n",
        "        model.train()\n",
        "\n",
        "        for batch, (img, label) in enumerate(dataloader):\n",
        "            if batch <= 936:\n",
        "                pred = model(img)\n",
        "                loss = loss_fn(pred, label)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                if batch % 100 == 0:\n",
        "                    loss, current = loss.item(), batch * len(img)\n",
        "                    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "                    avg_loss += loss\n",
        "        avg_loss /= 10\n",
        "        print(f\"Average loss on the epoch {epoch+1}: {avg_loss:>7f}\")\n",
        "        if avg_loss >= best_loss * 1.1:\n",
        "            break\n",
        "        best_loss = min(best_loss, avg_loss)\n",
        "    torch.save(model.state_dict(), 'model_weights.pth')\n",
        "    print(f\"The model with the best loss({best_loss}) has been saved.\")"
      ],
      "metadata": {
        "id": "OEYMghOdhtmu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "BI72wuyqi8LY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_dataloader, optimizer, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqzZQ7WDjVr8",
        "outputId": "bf2e5408-031c-4f7c-a490-2f5f38d412cc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Epoch 1 =======\n",
            "loss: 2.314101  [    0/60000]\n",
            "loss: 0.152175  [ 6400/60000]\n",
            "loss: 0.131183  [12800/60000]\n",
            "loss: 0.049104  [19200/60000]\n",
            "loss: 0.139492  [25600/60000]\n",
            "loss: 0.116373  [32000/60000]\n",
            "loss: 0.091498  [38400/60000]\n",
            "loss: 0.058595  [44800/60000]\n",
            "loss: 0.027748  [51200/60000]\n",
            "loss: 0.031674  [57600/60000]\n",
            "Average loss on the epoch 1: 0.311194\n",
            "======= Epoch 2 =======\n",
            "loss: 0.032532  [    0/60000]\n",
            "loss: 0.110173  [ 6400/60000]\n",
            "loss: 0.032906  [12800/60000]\n",
            "loss: 0.111668  [19200/60000]\n",
            "loss: 0.013076  [25600/60000]\n",
            "loss: 0.223117  [32000/60000]\n",
            "loss: 0.014135  [38400/60000]\n",
            "loss: 0.043407  [44800/60000]\n",
            "loss: 0.046399  [51200/60000]\n",
            "loss: 0.059730  [57600/60000]\n",
            "Average loss on the epoch 2: 0.068714\n",
            "======= Epoch 3 =======\n",
            "loss: 0.004017  [    0/60000]\n",
            "loss: 0.020048  [ 6400/60000]\n",
            "loss: 0.006699  [12800/60000]\n",
            "loss: 0.058302  [19200/60000]\n",
            "loss: 0.086906  [25600/60000]\n",
            "loss: 0.086484  [32000/60000]\n",
            "loss: 0.034257  [38400/60000]\n",
            "loss: 0.008417  [44800/60000]\n",
            "loss: 0.182762  [51200/60000]\n",
            "loss: 0.018170  [57600/60000]\n",
            "Average loss on the epoch 3: 0.050606\n",
            "======= Epoch 4 =======\n",
            "loss: 0.066885  [    0/60000]\n",
            "loss: 0.083327  [ 6400/60000]\n",
            "loss: 0.004729  [12800/60000]\n",
            "loss: 0.015608  [19200/60000]\n",
            "loss: 0.010560  [25600/60000]\n",
            "loss: 0.070835  [32000/60000]\n",
            "loss: 0.002038  [38400/60000]\n",
            "loss: 0.002454  [44800/60000]\n",
            "loss: 0.045648  [51200/60000]\n",
            "loss: 0.020670  [57600/60000]\n",
            "Average loss on the epoch 4: 0.032276\n",
            "======= Epoch 5 =======\n",
            "loss: 0.028521  [    0/60000]\n",
            "loss: 0.160019  [ 6400/60000]\n",
            "loss: 0.019409  [12800/60000]\n",
            "loss: 0.040353  [19200/60000]\n",
            "loss: 0.160588  [25600/60000]\n",
            "loss: 0.016873  [32000/60000]\n",
            "loss: 0.029220  [38400/60000]\n",
            "loss: 0.000503  [44800/60000]\n",
            "loss: 0.016493  [51200/60000]\n",
            "loss: 0.067930  [57600/60000]\n",
            "Average loss on the epoch 5: 0.053991\n",
            "The model with the best loss(0.032275547785684464) has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK0XXyShpNBL",
        "outputId": "21fd4832-8f9b-4b94-e10d-b40945ec2045"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "hEzgFCA7OiAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)-1\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (X, y) in enumerate(dataloader):\n",
        "            if i <= 155:\n",
        "                pred = model(X)\n",
        "                test_loss += loss_fn(pred, y).item()\n",
        "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "rYzaK4ZSpfXl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, test_dataloader, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4-8BvH4PFxy",
        "outputId": "adcff9f4-c88e-47b4-83f5-49baed9f49b7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 98.5%, Avg loss: 0.045296 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}